# Cognitive Core

Composable AI workflows from eight cognitive primitives.
Three-layer architecture: **Workflow** Ã— **Domain** Ã— **Case**.
Platform-agnostic â€” runs on Google, Azure, OpenAI, or Bedrock.

## Quick Start

```bash
pip install -r requirements.txt

# Install ONE provider:
pip install langchain-google-genai     # Google Gemini
pip install langchain-openai           # Azure OpenAI / OpenAI
pip install langchain-aws              # Amazon Bedrock

# Set credentials for your provider:
export GOOGLE_API_KEY=your_key                          # Google
# â€” or â€”
export AZURE_OPENAI_ENDPOINT=https://your.openai.azure.com  # Azure
export AZURE_OPENAI_API_KEY=your_key
# â€” or â€”
export OPENAI_API_KEY=your_key                          # OpenAI
# â€” or â€”
export AWS_DEFAULT_REGION=us-east-1                     # Bedrock

# Card dispute (fraud)
python -m engine.runner \
  -w workflows/dispute_resolution.yaml \
  -d domains/card_dispute.yaml \
  -c cases/card_clear_fraud.json

# SAR investigation (structuring)
python -m engine.runner \
  -w workflows/sar_investigation.yaml \
  -d domains/structuring_sar.yaml \
  -c cases/sar_structuring.json

# Loan hardship (military transition)
python -m engine.runner \
  -w workflows/loan_hardship.yaml \
  -d domains/military_hardship.yaml \
  -c cases/military_hardship_reeves.json

# Check clearing complaint with Act primitive
python -m engine.runner \
  -w workflows/complaint_resolution_act.yaml \
  -d domains/check_clearing_complaint.yaml \
  -c cases/check_clearing_complaint_diouf.json

# For live email delivery via Act primitive (optional):
export SMTP_SENDER=your-email@gmail.com
export SMTP_APP_PASSWORD=your-app-password
# SMTP_HOST and SMTP_PORT default to smtp.gmail.com:587
```

## Three-Layer Architecture

```
workflows/               domains/                 cases/
  dispute_resolution â”€â”€â†’   card_dispute        â”€â”€â†’  card_clear_fraud.json
                     â”€â”€â†’   ach_dispute          â”€â”€â†’  ach_revoked_authorization.json
  sar_investigation  â”€â”€â†’   structuring_sar      â”€â”€â†’  sar_structuring.json
  regulatory_impact  â”€â”€â†’   avm_regulation       â”€â”€â†’  avm_regulation.json
  loan_hardship      â”€â”€â†’   military_hardship    â”€â”€â†’  military_hardship_reeves.json
  nurse_triage       â”€â”€â†’   cardiac_triage       â”€â”€â†’  cardiac_chest_pain.json
  spending_advisor   â”€â”€â†’   debit_spending       â”€â”€â†’  spending_advisor_williams.json
  complaint_res_act  â”€â”€â†’   check_clearing       â”€â”€â†’  check_clearing_complaint_diouf.json
```

**Workflow** â€” the cognitive pattern. Which primitives, in what order,
with what transitions. Reusable across domains. Owned by AI engineers.

**Domain** â€” the subject matter expertise. Categories, rules, constraints.
Domain-specific but case-independent. Owned by SMEs.

**Case** â€” runtime data. The specific member, transaction, patient.
Comes from production systems. Never hand-edited in prod.

Multiplication: workflows Ã— domains Ã— unlimited cases.

## Primitives

| # | Primitive       | Question               | Key Output Fields                   | Boundary |
|---|-----------------|------------------------|-------------------------------------|----------|
| 1 | **Retrieve**    | What data exists?      | data, sources_queried, retrieval_plan | Read     |
| 2 | **Classify**    | What is this?          | category, confidence, alternatives  | Read     |
| 3 | **Investigate** | What's true here?      | finding, hypotheses, actions        | Read     |
| 4 | **Think**       | What should we do?     | thought, conclusions, decision      | Read     |
| 5 | **Verify**      | Does this conform?     | conforms, violations, rules_checked | Read     |
| 6 | **Generate**    | Write this properly    | artifact, constraints_checked       | Read     |
| 7 | **Challenge**   | Can this survive?      | survives, vulnerabilities, strengths| Read     |
| 8 | **Act**         | Execute this action    | actions_taken, authorization_checks | **Write**|

Primitives 1â€“7 are read-only. Only Act (8) crosses the read-write boundary,
with authorization enforcement, dry-run by default, and reversibility declarations.

## LLM Provider Configuration

The framework auto-detects your provider from environment variables.
No code changes needed to switch providers.

### Model Aliases

YAML configs and CLI use logical aliases that resolve per-provider:

| Alias      | Google            | Azure / OpenAI | Bedrock                |
|------------|-------------------|----------------|------------------------|
| `default`  | gemini-2.0-flash  | gpt-4o-mini    | claude-3.5-haiku       |
| `fast`     | gemini-2.0-flash  | gpt-4o-mini    | claude-3.5-haiku       |
| `standard` | gemini-2.5-pro    | gpt-4o         | claude-3.5-sonnet      |
| `strong`   | gemini-2.5-pro    | gpt-4o         | claude-3.5-sonnet      |

Provider-specific model names also work as pass-through:
```bash
python -m engine.runner -m gpt-4o ...       # auto-detects OpenAI/Azure
python -m engine.runner -m gemini-2.5-pro ...  # auto-detects Google
```

### Environment Overrides

```bash
LLM_PROVIDER=azure          # Force provider (skip auto-detection)
LLM_DEFAULT_MODEL=gpt-4.1   # Override what "default" resolves to
```

## Agentic Capabilities

Two execution modes:

- **Sequential** (production): Steps in predetermined order with
  deterministic or LLM-assisted routing
- **Agentic** (discovery): LLM orchestrator chooses step sequence
  at runtime using hub-and-spoke graph

Sequential workflows support three transition modes per step:

- **Deterministic** (`when`/`goto`) â€” evaluated first, no LLM call
- **Agent** (`agent_decide`) â€” LLM chooses among options
- **Default** â€” fallback if nothing else matches

Plus: loops with `max_loops`, early termination with `__end__`,
escalation paths to human specialists.

## Live Tracing

Every run shows real-time progress:

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  dispute_resolution_card_dispute  (three-layer)
  provider: azure  model: gpt-4o-mini
  steps: classify_dispute_type â†’ verify_against_records â†’ ...
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  [  0.0s] ğŸ·ï¸  classify_dispute_type
  [  0.1s]     â†³ calling LLM (2,341 chars)...
  [  3.2s]     â†³ response received (847 chars, 3.1s)
  [  3.2s]     â†’ unauthorized_transaction (confidence: 0.95)
  [  3.2s]     âš¡ route â†’ classify_resolution_fast (deterministic)
  [  3.2s] ğŸ·ï¸  classify_resolution_fast
  ...
```

Disable with `--no-trace`.

## CLI Reference

```
python -m engine.runner -w WORKFLOW -d DOMAIN -c CASE [options]

Options:
  -w, --workflow    Workflow YAML
  -d, --domain      Domain YAML
  -c, --case        Case JSON/YAML
  -m, --model       Model alias (default/fast/standard/strong) or
                    provider-specific name (gpt-4o, gemini-2.0-flash)
  -p, --provider    Force provider: google, azure, openai, bedrock
  -v, --verbose     Detailed output
  -o, --output      Save full state to JSON
  --no-trace        Disable live progress
  --validate-only   Check config without running
```

## Project Structure

```
cognitive-core/
â”œâ”€â”€ engine/
â”‚   â”œâ”€â”€ llm.py          # Provider factory â€” single point of LLM construction
â”‚   â”œâ”€â”€ composer.py      # Three-layer merge + LangGraph compilation
â”‚   â”œâ”€â”€ nodes.py         # Primitive execution + tracing
â”‚   â”œâ”€â”€ agentic.py       # Hub-and-spoke orchestrator for agentic mode
â”‚   â”œâ”€â”€ runner.py        # CLI with live trace
â”‚   â”œâ”€â”€ state.py         # Shared workflow state + parameter resolution
â”‚   â”œâ”€â”€ actions.py       # Action registry with authorization enforcement
â”‚   â”œâ”€â”€ tools.py         # Tool registry for Retrieve primitive
â”‚   â””â”€â”€ providers.py     # API, Vector, and MCP tool providers
â”œâ”€â”€ registry/
â”‚   â”œâ”€â”€ primitives.py    # Primitive registry + prompt rendering
â”‚   â”œâ”€â”€ schemas.py       # Pydantic output contracts
â”‚   â””â”€â”€ prompts/         # Base prompt templates (9 files)
â”œâ”€â”€ mcp_servers/
â”‚   â”œâ”€â”€ compliance_server.py  # Read-side MCP server
â”‚   â””â”€â”€ actions_server.py     # Write-side MCP server
â”œâ”€â”€ workflows/           # Layer 1: cognitive patterns (7 sequential + 2 agentic)
â”œâ”€â”€ domains/             # Layer 2: subject matter expertise (10 configs)
â”œâ”€â”€ cases/               # Layer 3: runtime data (9 case files)
â””â”€â”€ requirements.txt
```
